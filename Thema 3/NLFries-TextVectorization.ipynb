{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nederlands-Fries\n",
    "\n",
    "- https://leren.windesheim.nl/d2l/le/lessons/103162/topics/927096"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 1. Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vertaal Nederlandse zinnen naar het Fries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "School heeft ons al de code aangeleverd die een tekstcorpus van het Fryske Akademy downloadt, alsook deze gegevens omgezet naar een CSV-bestand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Bibliotheken importeren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_nlp in /usr/local/lib/python3.11/dist-packages (0.15.1)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras_nlp) (2.1.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras_nlp) (1.26.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras_nlp) (24.1)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from keras_nlp) (2024.9.11)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras_nlp) (13.7.1)\n",
      "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (from keras_nlp) (0.3.1)\n",
      "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.11/dist-packages (from keras_nlp) (2.17.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub->keras_nlp) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub->keras_nlp) (4.66.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras_nlp) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras_nlp) (2.18.0)\n",
      "Requirement already satisfied: tensorflow<2.18,>=2.17.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-text->keras_nlp) (2.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras_nlp) (0.1.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (4.25.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (70.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (2.17.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (3.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (0.37.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras_nlp) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras_nlp) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras_nlp) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras_nlp) (2024.7.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (0.43.0)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (0.0.8)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (0.12.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (2.1.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install keras_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 20:17:31.442251: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-13 20:17:31.454732: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-13 20:17:31.458537: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-13 20:17:31.469387: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import keras\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras_nlp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_logger().setLevel('INFO')\n",
    "tf.autograph.set_verbosity(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"NederlandsFries.ipynb\" not in os.listdir('.'):\n",
    "    os.chdir(\"Thema 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Inlezen `dataset.csv`\n",
    "De corpus bevat twee simpele kolommen, een met de Nederlandse tekst, en een met de Friese vertaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 173912 entries, 0 to 173911\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   nederlands  173912 non-null  object\n",
      " 1   fries       173912 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nederlands</th>\n",
       "      <th>fries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we hebben de burgemeester het advies gegeven o...</td>\n",
       "      <td>wy hawwe de boargemaster it advys jun om it ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>we hebben de burgemeester het advies gegeven o...</td>\n",
       "      <td>wy hawwe de boargemaster it advys jun om it ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>een plotselinge dood</td>\n",
       "      <td>in hastige dea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>een plotselinge dood</td>\n",
       "      <td>in unferwachte dea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zijn plotseling overlijden</td>\n",
       "      <td>syn hastich ferstjerren</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          nederlands  \\\n",
       "0  we hebben de burgemeester het advies gegeven o...   \n",
       "1  we hebben de burgemeester het advies gegeven o...   \n",
       "2                               een plotselinge dood   \n",
       "3                               een plotselinge dood   \n",
       "4                         zijn plotseling overlijden   \n",
       "\n",
       "                                               fries  \n",
       "0  wy hawwe de boargemaster it advys jun om it ka...  \n",
       "1  wy hawwe de boargemaster it advys jun om it ka...  \n",
       "2                                     in hastige dea  \n",
       "3                                 in unferwachte dea  \n",
       "4                            syn hastich ferstjerren  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df = pd.read_csv(\"Data/dataset.csv\")\n",
    "dataset_df.info()\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Inzicht zinlengte\n",
    "We zien dat de teksten maximaal 60 woorden bevatten, en gemiddeld 9 woorden. Gelukkig niet te veel, zo kunnen we hem makkelijker trainen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min 1 Max 59 gemiddeld 9.066044896269378\n"
     ]
    }
   ],
   "source": [
    "hoeveelheid_woorden_nederlands = dataset_df['nederlands'].apply(lambda txt: len(txt.split()))\n",
    "print(f\"Min {hoeveelheid_woorden_nederlands.min()} Max {hoeveelheid_woorden_nederlands.max()} gemiddeld {hoeveelheid_woorden_nederlands.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min 1 Max 60 gemiddeld 9.237137172823036\n"
     ]
    }
   ],
   "source": [
    "hoeveelheid_woorden_fries = dataset_df['fries'].apply(lambda txt: len(txt.split()))\n",
    "print(f\"Min {hoeveelheid_woorden_fries.min()} Max {hoeveelheid_woorden_fries.max()} gemiddeld {hoeveelheid_woorden_fries.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Inzicht woordhoeveelheid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70245"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(np.hstack(dataset_df['nederlands'].apply(lambda txt: np.array(txt.split())))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74319"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(np.hstack(dataset_df['fries'].apply(lambda txt: np.array(txt.split())))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tekst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Start en eindtokens toevoegen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOKEN = \"[begin]\"\n",
    "END_TOKEN = \"[eind]\"\n",
    "\n",
    "def omringMetBeginEnEinde(tekst):\n",
    "    return f\"{START_TOKEN} {tekst} {END_TOKEN}\"\n",
    "\n",
    "dataset_df['fries'] = dataset_df['fries'].apply(omringMetBeginEnEinde)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Splitsen tussen traindata testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nederlands</th>\n",
       "      <th>fries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16812</th>\n",
       "      <td>een grijze dag</td>\n",
       "      <td>[BEGIN] in skiere dei [EIND]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146080</th>\n",
       "      <td>met de ineenstorting van het habsburgse rijk n...</td>\n",
       "      <td>[BEGIN] mei it yninoarstoarten fan it habsboar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20822</th>\n",
       "      <td>een aardappel kost hier een euro per stuk en i...</td>\n",
       "      <td>[BEGIN] in ierappel jildt hjir in euro it stik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167769</th>\n",
       "      <td>vanochtend lag ik al half wakker me af te vrag...</td>\n",
       "      <td>[BEGIN] fan e moarn lei ik al heal wekker my o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115503</th>\n",
       "      <td>u kunt zeker zijn van zorgvuldigheid en kwaliteit</td>\n",
       "      <td>[BEGIN] jo kinne wis weze fan soarchfaldichhei...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               nederlands  \\\n",
       "16812                                      een grijze dag   \n",
       "146080  met de ineenstorting van het habsburgse rijk n...   \n",
       "20822   een aardappel kost hier een euro per stuk en i...   \n",
       "167769  vanochtend lag ik al half wakker me af te vrag...   \n",
       "115503  u kunt zeker zijn van zorgvuldigheid en kwaliteit   \n",
       "\n",
       "                                                    fries  \n",
       "16812                        [BEGIN] in skiere dei [EIND]  \n",
       "146080  [BEGIN] mei it yninoarstoarten fan it habsboar...  \n",
       "20822   [BEGIN] in ierappel jildt hjir in euro it stik...  \n",
       "167769  [BEGIN] fan e moarn lei ik al heal wekker my o...  \n",
       "115503  [BEGIN] jo kinne wis weze fan soarchfaldichhei...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_dutch, test_dutch, train_frisian, test_frisian = train_test_split(\n",
    "#     dataset_df['nederlands'], dataset_df['fries'],\n",
    "#     test_size=0.2,\n",
    "#     shuffle = True,\n",
    "# )\n",
    "\n",
    "train_pairs, test_pairs = train_test_split(\n",
    "    dataset_df,\n",
    "    test_size=0.2,\n",
    "    shuffle = True,\n",
    ")\n",
    "\n",
    "train_pairs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Tekstvectorisatie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dutch_vocab_size   = 20000\n",
    "frisian_vocab_size = 20000\n",
    "\n",
    "dutch_maxlen   = 20\n",
    "frisian_maxlen = 20\n",
    "\n",
    "strip_chars = string.punctuation + \"Â¿\"\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728850658.094887   25003 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728850658.112269   25003 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728850658.112312   25003 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728850658.114011   25003 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728850658.114041   25003 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728850658.114060   25003 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728850658.251235   25003 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728850658.251303   25003 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-13 20:17:38.251316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1728850658.251394   25003 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-13 20:17:38.251425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5008 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:06:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dutch_text_vectorization = layers.TextVectorization(\n",
    "    max_tokens=dutch_vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=dutch_maxlen,\n",
    ")\n",
    "dutch_text_vectorization.adapt(dataset_df['nederlands'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "frisian_text_vectorization = layers.TextVectorization(\n",
    "    max_tokens=frisian_vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=frisian_maxlen + 1, # <--- om ervoor te zorgen dat hij de volgende gaat voorspellen\n",
    "    standardize=custom_standardization,\n",
    ")\n",
    "frisian_text_vectorization.adapt(dataset_df['fries'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "def format_dataset(dutch, frisian):\n",
    "    dutch = dutch_text_vectorization(dutch)\n",
    "    frisian = frisian_text_vectorization(frisian)\n",
    "\n",
    "    return ({\n",
    "        \"dutch\": dutch,\n",
    "        \"frisian\": frisian[:, :-1],\n",
    "    }, frisian[:, 1:])\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    dutch_texts = pairs['nederlands']\n",
    "    frisian_texts = pairs['fries']\n",
    "    dutch_texts = list(dutch_texts)\n",
    "    frisian_texts = list(frisian_texts)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dutch_texts, frisian_texts))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset, num_parallel_calls=16)\n",
    "    return dataset.shuffle(2048).prefetch(16).cache() #in memory caching ivm performance\n",
    "\n",
    "train_ds = make_dataset(train_pairs)\n",
    "test_ds = make_dataset(test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs['dutch'].shape: (64, 20)\n",
      "inputs['frisian'].shape: (64, 20)\n",
      "targets.shape: (64, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 20:17:48.927142: W tensorflow/core/kernels/data/cache_dataset_ops.cc:913] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 20:17:48.930136: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds.take(1):\n",
    "    print(f\"inputs['dutch'].shape: {inputs['dutch'].shape}\")\n",
    "    print(f\"inputs['frisian'].shape: {inputs['frisian'].shape}\")\n",
    "    print(f\"targets.shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'dutch': <tf.Tensor: shape=(64, 20), dtype=int64, numpy=\n",
      "array([[1274,   23,    3, ...,    0,    0,    0],\n",
      "       [  57,    9,   49, ...,    0,    0,    0],\n",
      "       [  70,    2, 2195, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  51, 2841,  223, ...,    0,    0,    0],\n",
      "       [4507,    6, 4843, ...,    0,    0,    0],\n",
      "       [  14,   47,    2, ...,    0,    0,    0]])>, 'frisian': <tf.Tensor: shape=(64, 20), dtype=int64, numpy=\n",
      "array([[   3, 1274,   20, ...,    0,    0,    0],\n",
      "       [   3,    5,   79, ...,    0,    0,    0],\n",
      "       [   3,   35,    4, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [   3,   64, 2693, ...,    0,    0,    0],\n",
      "       [   3, 4306,    8, ...,    2,    0,    0],\n",
      "       [   3,   33,    4, ...,    0,    0,    0]])>}, <tf.Tensor: shape=(64, 20), dtype=int64, numpy=\n",
      "array([[1274,   20,    5, ...,    0,    0,    0],\n",
      "       [   5,   79,   11, ...,    0,    0,    0],\n",
      "       [  35,    4, 2938, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [  64, 2693,  290, ...,    0,    0,    0],\n",
      "       [4306,    8, 4532, ...,    0,    0,    0],\n",
      "       [  33,    4, 4026, ...,    0,    0,    0]])>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 20:17:49.179485: W tensorflow/core/kernels/data/cache_dataset_ops.cc:913] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 20:17:49.181927: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for x in train_ds.take(1):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dutch   = tf.data.Dataset.from_tensor_slices(tf.cast(train_dutch.values, tf.string)).batch(64)\n",
    "# test_dutch    = tf.data.Dataset.from_tensor_slices(tf.cast(test_dutch.values, tf.string)).batch(64)\n",
    "# train_frisian = tf.data.Dataset.from_tensor_slices(tf.cast(train_frisian.values, tf.string)).batch(64)\n",
    "# test_frisian  = tf.data.Dataset.from_tensor_slices(tf.cast(test_frisian.values, tf.string)).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print([x for x in train_dutch.take(1)][0][0])\n",
    "# print([x for x in train_frisian.take(1)][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds = tf.data.Dataset.zip((train_dutch,train_frisian))\n",
    "# test_ds = tf.data.Dataset.zip((test_dutch,test_frisian))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int_train_ds = train_ds.map(\n",
    "#     lambda x, y: (dutch_text_vectorization(x), frisian_text_vectorization(y)),\n",
    "#     num_parallel_calls=16)\n",
    "\n",
    "# int_test_ds = test_ds.map(\n",
    "#     lambda x, y: (dutch_text_vectorization(x), frisian_text_vectorization(y)),\n",
    "#     num_parallel_calls=16)\n",
    "\n",
    "# print(np.array([x for x in int_train_ds.take(1)]).shape)\n",
    "# print(int_train_ds)\n",
    "# # print([x for x in int_test_ds.take(1)][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tekst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Initialize the embeddings for tokens and positions\n",
    "        self.token_embeddings = layers.Embedding(           # regular embedding\n",
    "            input_dim=input_dim, output_dim=output_dim)\n",
    "        self.position_embeddings = layers.Embedding(        # position embedding\n",
    "            input_dim=sequence_length, output_dim=output_dim)\n",
    "        # Some relevant settings for subsequent layers\n",
    "        # Definnig the settings as part of the object (self.) makes it\n",
    "        # easier to apply them consistently in the call() method\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]                               # Length of the input sentences\n",
    "        positions = tf.range(start=0, limit=length, delta=1)        # 0-indexed positions of tokens in the sequences\n",
    "        # Generate the actual position embeddings\n",
    "        embedded_tokens = self.token_embeddings(inputs)             # Regular embeddings of the tokens\n",
    "        embedded_positions = self.position_embeddings(positions)    # Position embeddings\n",
    "        # We maken hier een 2e embeddingspace voor de positie die we daarna bij het origineel optellen\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return keras.ops.not_equal(inputs, 0) #geneer mask basis van waar de input niet 0 is.Zodat we de input niet hoeven te padden\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"output_dim\": self.output_dim,\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "            \"input_dim\": self.input_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):                              # Our transformer encoder layer inherits from keras.layers.Layer\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):   # the constructor of our encoder layer\n",
    "        super().__init__(**kwargs)                                   # calls the constructor of the parent class (keras.layers.Layer)\n",
    "\n",
    "        # Store a whole bunch settings and initialise the building blocks for our encoder layer\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        # Multi-head attention building block\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        # Dense building block\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
    "             layers.Dense(embed_dim),]\n",
    "        )\n",
    "        # Layer normalisation building block, 1 and 2 are used to normalise the output of the attention and dense blocks respectively\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        # Here we actually build the encoder layer\n",
    "\n",
    "        # If we define a mask for attention, we need to perform some preprocessing on it\n",
    "        if mask is not None:\n",
    "            mask = mask[:, tf.newaxis, :] #padding mask (negeer alle paffing) voeg een dimensie toe. Transformer verwacht 3D of meer. Embedding layer genereerd 2d layer\n",
    "\n",
    "        # Define the attention part of the encoder\n",
    "        attention_output = self.attention(\n",
    "            inputs, inputs, attention_mask=mask)\n",
    "        # Apply layer normalisation to the attention output\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        # Apply the dense part of the encoder\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        # Apply layer normalisation to the dense output, and return the encoder\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "    def get_config(self):\n",
    "        # Return all the configuration settings for this layer\n",
    "\n",
    "        # Get the configuration settings from the parent class\n",
    "        config = super().get_config()\n",
    "        # Add the config settings of our own layer\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.attention_2 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
    "             layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "        self.supports_masking = True #anders geen masking mogelijk\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        #prevents the model from learning to copy the next token from the input to the output by hiden it\n",
    "        # [[1,0,0],\n",
    "        #  [1,1,0],\n",
    "        #  [1,1,1]]\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1),\n",
    "             tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
    "        #Replicate it along the batch axis to get an matrix of shape (batch_size, sequence_length, sequence_length)\n",
    "        return tf.tile(mask, mult)\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "        #retrieve the casual mask\n",
    "        padding_mask = None\n",
    "        if mask is not None: #prepare the input mask that describes padding locations in the target_sequence\n",
    "            padding_mask = keras.cast(\n",
    "                mask[:, tf.newaxis, :], dtype=\"int32\") #extra dim aangezien transfo deze verwacht\n",
    "            padding_mask = keras.minimum(padding_mask, causal_mask)#merge both masks (input padding en volgende woord padding)\n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=inputs,\n",
    "            value=inputs,\n",
    "            key=inputs,\n",
    "            attention_mask=causal_mask)# pass the casual mask tot the first attention layer, which performs self attention over the target sequence\n",
    "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "        attention_output_2 = self.attention_2(\n",
    "            query=attention_output_1,\n",
    "            value=encoder_outputs,\n",
    "            key=encoder_outputs,\n",
    "            attention_mask=padding_mask, #pass the combined mask to the second attention layer, which relates the source sequence to the target sequence\n",
    "        )\n",
    "        attention_output_2 = self.layernorm_2(\n",
    "            attention_output_1 + attention_output_2)\n",
    "        proj_output = self.dense_proj(attention_output_2)\n",
    "        return self.layernorm_3(attention_output_2 + proj_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.framework.ops import disable_eager_execution\n",
    "# disable_eager_execution()\n",
    "\n",
    "# import tensorflow.compat.v1 as tf\n",
    "# tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "embed_dim = 64\n",
    "dense_dim = 1024\n",
    "num_heads = 8\n",
    "\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(dutch_maxlen,), dtype=\"int64\", name=\"dutch\")\n",
    "decoder_inputs = keras.Input(shape=(frisian_maxlen,), dtype=\"int64\", name=\"frisian\")\n",
    "\n",
    "# encoder_embedding = TokenAndPositionEmbedding(dutch_vocab_size, dutch_maxlen, embed_dim)(encoder_inputs)\n",
    "encoder_embedding = PositionalEmbedding(dutch_maxlen, dutch_vocab_size, embed_dim, name=\"encoder_embedding\")(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads, name=\"encoder_outputs\")(encoder_embedding)\n",
    "\n",
    "\n",
    "# decoder_embedding = TokenAndPositionEmbedding(frisian_vocab_size, frisian_maxlen, embed_dim)(decoder_inputs)\n",
    "decoder_embedding = PositionalEmbedding(frisian_maxlen, frisian_vocab_size, embed_dim, name=\"decoder_embedding\")(decoder_inputs)\n",
    "decoder = TransformerDecoder(embed_dim, dense_dim, num_heads, name=\"decoder\")(decoder_embedding, encoder_outputs)\n",
    "\n",
    "\n",
    "decoder_dropout = layers.Dropout(0.5, name=\"decoder_dropout\")(decoder)\n",
    "decoder_outputs = layers.Dense(frisian_vocab_size, activation=\"softmax\", name=\"decoder_outputs\")(decoder_dropout)\n",
    "\n",
    "\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ter [ts](/usr/local/lib/python3.11/dist-packages/keras_nlp/src/layers/modeling/transformer_encoder.py)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.AdamW(5e-5),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    jit_compile=True,\n",
    ")\n",
    "history = model.fit(train_ds, epochs=3, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "acc=history.history['sparse_categorical_accuracy']\n",
    "val_acc=history.history['val_sparse_categorical_accuracy']\n",
    "epochs=range(1, len(acc)+1)\n",
    "plt.plot(epochs, acc, label='accuracy')\n",
    "plt.plot(epochs, val_acc, label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, ziet er veelbelovend uit! Nu snel maar eens een aantal extra keer bijtrainen:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "embed_dim = 64\n",
    "dense_dim = 1024\n",
    "num_heads = 8\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(dutch_maxlen,), dtype=\"int64\", name=\"dutch\")\n",
    "decoder_inputs = keras.Input(shape=(frisian_maxlen,), dtype=\"int64\", name=\"frisian\")\n",
    "encoder_embedding = PositionalEmbedding(dutch_maxlen, dutch_vocab_size, embed_dim, name=\"encoder_embedding\")(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads, name=\"encoder_outputs\")(encoder_embedding)\n",
    "decoder_embedding = PositionalEmbedding(frisian_maxlen, frisian_vocab_size, embed_dim, name=\"decoder_embedding\")(decoder_inputs)\n",
    "decoder = TransformerDecoder(embed_dim, dense_dim, num_heads, name=\"decoder\")(decoder_embedding, encoder_outputs)\n",
    "decoder_dropout = layers.Dropout(0.5, name=\"decoder_dropout\")(decoder)\n",
    "decoder_outputs = layers.Dense(frisian_vocab_size, activation=\"softmax\", name=\"decoder_outputs\")(decoder_dropout)\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# model.compile(\n",
    "#     loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#     optimizer=keras.optimizers.Adam(5e-5),\n",
    "#     metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "#     jit_compile=True,\n",
    "# )\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    "    jit_compile=True)\n",
    "history = model.fit(train_ds, epochs=30, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.x Meer params"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "embed_dim = 256\n",
    "dense_dim = 2024\n",
    "num_heads = 8\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(dutch_maxlen,), dtype=\"int64\", name=\"dutch\")\n",
    "decoder_inputs = keras.Input(shape=(frisian_maxlen,), dtype=\"int64\", name=\"frisian\")\n",
    "encoder_embedding = PositionalEmbedding(dutch_maxlen, dutch_vocab_size, embed_dim, name=\"encoder_embedding\")(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads, name=\"encoder_outputs\")(encoder_embedding)\n",
    "decoder_embedding = PositionalEmbedding(frisian_maxlen, frisian_vocab_size, embed_dim, name=\"decoder_embedding\")(decoder_inputs)\n",
    "decoder = TransformerDecoder(embed_dim, dense_dim, num_heads, name=\"decoder\")(decoder_embedding, encoder_outputs)\n",
    "decoder_dropout = layers.Dropout(0.5, name=\"decoder_dropout\")(decoder)\n",
    "decoder_outputs = layers.Dense(frisian_vocab_size, activation=\"softmax\", name=\"decoder_outputs\")(decoder_dropout)\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    "    # jit_compile=True\n",
    "    )\n",
    "history = model.fit(train_ds, epochs=30, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.x. Lagere dropout\n",
    "Gezien overfitting geen probleem is op het moment, probeer ik hem te verlagen."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "embed_dim = 256\n",
    "dense_dim = 2024\n",
    "num_heads = 8\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(dutch_maxlen,), dtype=\"int64\", name=\"dutch\")\n",
    "decoder_inputs = keras.Input(shape=(frisian_maxlen,), dtype=\"int64\", name=\"frisian\")\n",
    "encoder_embedding = PositionalEmbedding(dutch_maxlen, dutch_vocab_size, embed_dim, name=\"encoder_embedding\")(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads, name=\"encoder_outputs\")(encoder_embedding)\n",
    "decoder_embedding = PositionalEmbedding(frisian_maxlen, frisian_vocab_size, embed_dim, name=\"decoder_embedding\")(decoder_inputs)\n",
    "decoder = TransformerDecoder(embed_dim, dense_dim, num_heads, name=\"decoder\")(decoder_embedding, encoder_outputs)\n",
    "decoder_dropout = layers.Dropout(0.1, name=\"decoder_dropout\")(decoder)\n",
    "decoder_outputs = layers.Dense(frisian_vocab_size, activation=\"softmax\", name=\"decoder_outputs\")(decoder_dropout)\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]    )\n",
    "history = model.fit(train_ds, epochs=5, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "acc=history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "epochs=range(1, len(acc)+1)\n",
    "plt.plot(epochs, acc, label='accuracy')\n",
    "plt.plot(epochs, val_acc, label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.x. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "embed_dim = 256\n",
    "dense_dim = 2024\n",
    "num_heads = 8\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(dutch_maxlen,), dtype=\"int64\", name=\"dutch\")\n",
    "encoder_embedding = PositionalEmbedding(dutch_maxlen, dutch_vocab_size, embed_dim, name=\"encoder_embedding\")(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads, name=\"encoder_outputs\")(encoder_embedding)\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(frisian_maxlen,), dtype=\"int64\", name=\"frisian\")\n",
    "decoder_embedding = PositionalEmbedding(frisian_maxlen, frisian_vocab_size, embed_dim, name=\"decoder_embedding\")(decoder_inputs)\n",
    "decoder = TransformerDecoder(embed_dim, dense_dim, num_heads, name=\"decoder\")(decoder_embedding, encoder_outputs)\n",
    "decoder_dropout = layers.Dropout(0.5, name=\"decoder_dropout\")(decoder)\n",
    "decoder_outputs = layers.Dense(frisian_vocab_size, activation=\"softmax\", name=\"decoder_outputs\")(decoder_dropout)\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]    )\n",
    "history = model.fit(train_ds, epochs=30, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#nog even testen\n",
    "import numpy as np\n",
    "import random\n",
    "fy_vocab = frisian_text_vectorization.get_vocabulary()\n",
    "fy_index_lookup = dict(zip(range(len(fy_vocab)), fy_vocab))\n",
    "max_decoded_sentence_length = 20\n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = dutch_text_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = frisian_text_vectorization(\n",
    "            [decoded_sentence])\n",
    "        predictions = model(\n",
    "            [tokenized_input_sentence, tokenized_target_sentence])\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = fy_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence\n",
    "\n",
    "test_dutch_texts = [pair[0] for pair in test_pairs]\n",
    "for _ in range(20):\n",
    "    input_sentence = random.choice(test_dutch_texts)\n",
    "    print(\"-\")\n",
    "    print(input_sentence)\n",
    "    print(decode_sequence(input_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZONDAG"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "embed_dim = 512\n",
    "dense_dim = 1024\n",
    "num_heads = 8\n",
    "\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(dutch_maxlen,), dtype=\"int64\", name=\"dutch\")\n",
    "decoder_inputs = keras.Input(shape=(frisian_maxlen,), dtype=\"int64\", name=\"frisian\")\n",
    "\n",
    "# encoder_embedding = TokenAndPositionEmbedding(dutch_vocab_size, dutch_maxlen, embed_dim)(encoder_inputs)\n",
    "encoder_embedding = PositionalEmbedding(dutch_maxlen, dutch_vocab_size, embed_dim, name=\"encoder_embedding\")(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads, name=\"encoder_outputs\")(encoder_embedding)\n",
    "\n",
    "\n",
    "# decoder_embedding = TokenAndPositionEmbedding(frisian_vocab_size, frisian_maxlen, embed_dim)(decoder_inputs)\n",
    "decoder_embedding = PositionalEmbedding(frisian_maxlen, frisian_vocab_size, embed_dim, name=\"decoder_embedding\")(decoder_inputs)\n",
    "decoder = TransformerDecoder(embed_dim, dense_dim, num_heads, name=\"decoder\")(decoder_embedding, encoder_outputs)\n",
    "\n",
    "\n",
    "decoder_dropout = layers.Dropout(0.5, name=\"decoder_dropout\")(decoder)\n",
    "decoder_outputs = layers.Dense(frisian_vocab_size, activation=\"softmax\", name=\"decoder_outputs\")(decoder_dropout)\n",
    "\n",
    "\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# model.compile(\n",
    "#     loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#     optimizer=keras.optimizers.AdamW(5e-5),\n",
    "#     metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "#     jit_compile=True,\n",
    "# )\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "history = model.fit(train_ds, epochs=3, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MASKED LOSS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "embed_dim = 128\n",
    "dense_dim = 1024\n",
    "num_heads = 8\n",
    "\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(dutch_maxlen,), dtype=\"int64\", name=\"dutch\")\n",
    "decoder_inputs = keras.Input(shape=(frisian_maxlen,), dtype=\"int64\", name=\"frisian\")\n",
    "\n",
    "# encoder_embedding = TokenAndPositionEmbedding(dutch_vocab_size, dutch_maxlen, embed_dim)(encoder_inputs)\n",
    "encoder_embedding = PositionalEmbedding(dutch_maxlen, dutch_vocab_size, embed_dim, name=\"encoder_embedding\")(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads, name=\"encoder_outputs\")(encoder_embedding)\n",
    "\n",
    "\n",
    "# decoder_embedding = TokenAndPositionEmbedding(frisian_vocab_size, frisian_maxlen, embed_dim)(decoder_inputs)\n",
    "decoder_embedding = PositionalEmbedding(frisian_maxlen, frisian_vocab_size, embed_dim, name=\"decoder_embedding\")(decoder_inputs)\n",
    "decoder = TransformerDecoder(embed_dim, dense_dim, num_heads, name=\"decoder\")(decoder_embedding, encoder_outputs)\n",
    "\n",
    "\n",
    "decoder_dropout = layers.Dropout(0.5, name=\"decoder_dropout\")(decoder)\n",
    "decoder_outputs = layers.Dense(frisian_vocab_size, activation=\"softmax\", name=\"decoder_outputs\")(decoder_dropout)\n",
    "\n",
    "\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss(label, pred):\n",
    "  mask = label != 0\n",
    "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "  loss = loss_object(label, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss.dtype)\n",
    "  loss *= mask\n",
    "\n",
    "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "  return loss\n",
    "\n",
    "\n",
    "def masked_accuracy(label, pred):\n",
    "  pred = tf.argmax(pred, axis=2)\n",
    "  label = tf.cast(label, pred.dtype)\n",
    "  match = label == pred\n",
    "\n",
    "  mask = label != 0\n",
    "\n",
    "  match = match & mask\n",
    "\n",
    "  match = tf.cast(match, dtype=tf.float32)\n",
    "  mask = tf.cast(mask, dtype=tf.float32)\n",
    "  return tf.reduce_sum(match)/tf.reduce_sum(mask)\n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    step = tf.cast(step, dtype=tf.float32)\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n",
    "\n",
    "learning_rate = CustomSchedule(embed_dim)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)\n",
    "\n",
    "model.compile(\n",
    "    loss=masked_loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[masked_accuracy])\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "history = model.fit(train_ds, epochs=3, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#nog even testen\n",
    "import numpy as np\n",
    "import random\n",
    "fy_vocab = frisian_text_vectorization.get_vocabulary()\n",
    "fy_index_lookup = dict(zip(range(len(fy_vocab)), fy_vocab))\n",
    "max_decoded_sentence_length = 20\n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = dutch_text_vectorization([input_sentence])\n",
    "    decoded_sentence = START_TOKEN\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = frisian_text_vectorization(\n",
    "            [decoded_sentence])\n",
    "        predictions = model(\n",
    "            [tokenized_input_sentence, tokenized_target_sentence])\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = fy_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token + str(sampled_token_index)\n",
    "        if sampled_token == END_TOKEN:\n",
    "            break\n",
    "    return decoded_sentence\n",
    "\n",
    "test_dutch_texts = [pair[0] for pair in test_pairs]\n",
    "for _ in range(20):\n",
    "    input_sentence = random.choice(test_dutch_texts)\n",
    "    print(\"-\")\n",
    "    print(input_sentence)\n",
    "    print(decode_sequence(input_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beter"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "embed_dim = 128\n",
    "dense_dim = 1024\n",
    "num_heads = 8\n",
    "\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(dutch_maxlen,), dtype=\"int64\", name=\"dutch\")\n",
    "decoder_inputs = keras.Input(shape=(frisian_maxlen,), dtype=\"int64\", name=\"frisian\")\n",
    "\n",
    "# encoder_embedding = TokenAndPositionEmbedding(dutch_vocab_size, dutch_maxlen, embed_dim)(encoder_inputs)\n",
    "encoder_embedding = PositionalEmbedding(dutch_maxlen, dutch_vocab_size, embed_dim, name=\"encoder_embedding\")(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads, name=\"encoder_outputs\")(encoder_embedding)\n",
    "\n",
    "\n",
    "# decoder_embedding = TokenAndPositionEmbedding(frisian_vocab_size, frisian_maxlen, embed_dim)(decoder_inputs)\n",
    "decoder_embedding = PositionalEmbedding(frisian_maxlen, frisian_vocab_size, embed_dim, name=\"decoder_embedding\")(decoder_inputs)\n",
    "decoder = TransformerDecoder(embed_dim, dense_dim, num_heads, name=\"decoder\")(decoder_embedding, encoder_outputs)\n",
    "\n",
    "\n",
    "decoder_dropout = layers.Dropout(0.5, name=\"decoder_dropout\")(decoder)\n",
    "decoder_outputs = layers.Dense(frisian_vocab_size, activation=\"softmax\", name=\"decoder_outputs\")(decoder_dropout)\n",
    "\n",
    "\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "learning_rate = CustomSchedule(embed_dim)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)\n",
    "\n",
    "model.compile(\n",
    "    loss=masked_loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[masked_accuracy])\n",
    "\n",
    "history = model.fit(train_ds, epochs=3, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#nog even testen\n",
    "import numpy as np\n",
    "import random\n",
    "fy_vocab = frisian_text_vectorization.get_vocabulary()\n",
    "fy_index_lookup = dict(zip(range(len(fy_vocab)), fy_vocab))\n",
    "max_decoded_sentence_length = 20\n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = dutch_text_vectorization([input_sentence])\n",
    "    decoded_sentence = START_TOKEN\n",
    "    indices = []\n",
    "\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence: tf.Tensor = frisian_text_vectorization([decoded_sentence])\n",
    "        tokenized_target_sentence = tokenized_target_sentence[:, :-1]\n",
    "        predictions = model([tokenized_input_sentence, tokenized_target_sentence])\n",
    "\n",
    "        # Pak altijd de laatste voorspelling\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        indices.append(sampled_token_index)\n",
    "\n",
    "        sampled_token = fy_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "\n",
    "        if sampled_token == END_TOKEN:\n",
    "            break\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "test_dutch_texts = [pair[0] for pair in test_pairs.values]\n",
    "for _ in range(5):\n",
    "    input_sentence = random.choice(test_dutch_texts)\n",
    "    print(\"-----------------------------------------------------------\")\n",
    "    print(\"NL:\", input_sentence)\n",
    "    print(\"FY:\", decode_sequence(input_sentence))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "embed_dim = 128\n",
    "dense_dim = 1024\n",
    "num_heads = 8\n",
    "\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(dutch_maxlen,), dtype=\"int64\", name=\"dutch\")\n",
    "decoder_inputs = keras.Input(shape=(frisian_maxlen,), dtype=\"int64\", name=\"frisian\")\n",
    "\n",
    "# encoder_embedding = TokenAndPositionEmbedding(dutch_vocab_size, dutch_maxlen, embed_dim)(encoder_inputs)\n",
    "encoder_embedding = PositionalEmbedding(dutch_maxlen, dutch_vocab_size, embed_dim, name=\"encoder_embedding\")(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads, name=\"encoder_outputs\")(encoder_embedding)\n",
    "\n",
    "\n",
    "# decoder_embedding = TokenAndPositionEmbedding(frisian_vocab_size, frisian_maxlen, embed_dim)(decoder_inputs)\n",
    "decoder_embedding = PositionalEmbedding(frisian_maxlen, frisian_vocab_size, embed_dim, name=\"decoder_embedding\")(decoder_inputs)\n",
    "decoder = TransformerDecoder(embed_dim, dense_dim, num_heads, name=\"decoder\")(decoder_embedding, encoder_outputs)\n",
    "\n",
    "\n",
    "decoder_dropout = layers.Dropout(0.5, name=\"decoder_dropout\")(decoder)\n",
    "decoder_outputs = layers.Dense(frisian_vocab_size, activation=\"softmax\", name=\"decoder_outputs\")(decoder_dropout)\n",
    "\n",
    "\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()\n",
    "\n",
    "learning_rate = CustomSchedule(embed_dim)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)\n",
    "\n",
    "model.compile(\n",
    "    loss=masked_loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[masked_accuracy])\n",
    "\n",
    "history = model.fit(train_ds, epochs=30, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7efd0462a350>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc=history.history['masked_accuracy']\n",
    "val_acc=history.history['val_masked_accuracy']\n",
    "epochs=range(1, len(acc)+1)\n",
    "plt.plot(epochs, acc, label='accuracy')\n",
    "plt.plot(epochs, val_acc, label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "NL: de australische wilhelmina van der heijden geen familie die toen in de kost was bij onze achterburen van e leende het me\n",
      "FY: de australise wilhelmina van der heijden gjin famylje dyt doe yn e kost wie by us efterbuorlju van e liende it my\n",
      "AI: de australyske ? van der ? gjin famylje dyt doe yn de kost wie by us ? fan de\n",
      "-----------------------------------------------------------\n",
      "NL: de besnijdenis geldt als een teken een beeld van de uitsnijding van de zonde\n",
      "FY: de besnijenis jildt as in teken in byld fan it fan de sunde\n",
      "AI: de ? jildt as in teken in byld fan de fan de skande\n",
      "-----------------------------------------------------------\n",
      "NL: ik at slecht en slapen ging niet veel beter\n",
      "FY: ik iet net en it sliepen gie net folle better\n",
      "AI: ik iet min en sliepen gie net folle better\n",
      "-----------------------------------------------------------\n",
      "NL: zij makelen en schakelen tussen de vraag van gezinnen en het beschikbare hulpaanbod\n",
      "FY: hja binne de spil tusken de fraach fan gesinnen en it beskikbere helpoanbod\n",
      "AI: hja ? en ? tusken de fraach fan hushaldingen en it beskikbere ?\n",
      "-----------------------------------------------------------\n",
      "NL: gedurende de avonduren en de nacht is daar niemand\n",
      "FY: op juntiid en nachts is der gjinien\n",
      "AI: yn e tiid fan e beskate nachts is der gjinien\n",
      "-----------------------------------------------------------\n",
      "NL: de landelijke overheid\n",
      "FY: de provinsjale oerheid\n",
      "AI: de provinsjale oerheid\n",
      "-----------------------------------------------------------\n",
      "NL: redacteur bij een uitgeverij\n",
      "FY: redakteur by in utjouwerij\n",
      "AI: redakteur by in ?\n",
      "-----------------------------------------------------------\n",
      "NL: een te kleine bal\n",
      "FY: in te lytse auto\n",
      "AI: in te lytse bal\n",
      "-----------------------------------------------------------\n",
      "NL: meer britse vrouwen dan mannen krijgen een lintje\n",
      "FY: mear britske froulju as manlju krije in lintsje\n",
      "AI: mear britske froulju as manlju krije jo hawwe\n",
      "-----------------------------------------------------------\n",
      "NL: een hogere macht\n",
      "FY: in hegere macht\n",
      "AI: in hegere macht\n"
     ]
    }
   ],
   "source": [
    "#nog even testen\n",
    "import numpy as np\n",
    "import random\n",
    "fy_vocab = frisian_text_vectorization.get_vocabulary()\n",
    "fy_index_lookup = dict(zip(range(len(fy_vocab)), fy_vocab))\n",
    "max_decoded_sentence_length = 20\n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = dutch_text_vectorization([input_sentence])\n",
    "    decoded_sentence = START_TOKEN\n",
    "    indices = []\n",
    "\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence: tf.Tensor = frisian_text_vectorization([decoded_sentence])\n",
    "        tokenized_target_sentence = tokenized_target_sentence[:, :-1]\n",
    "        predictions = model([tokenized_input_sentence, tokenized_target_sentence])\n",
    "\n",
    "        # Pak altijd de laatste voorspelling\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        indices.append(sampled_token_index)\n",
    "\n",
    "        sampled_token = fy_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "\n",
    "        if sampled_token == END_TOKEN:\n",
    "            break\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "def clean(str: str) -> str:\n",
    "    return str.lower().replace(START_TOKEN + ' ', '').replace(' ' + END_TOKEN, '').replace('[unk]', '?')\n",
    "\n",
    "for _ in range(10):\n",
    "    input_sentence, daadwerkelijk = random.choice(list(test_pairs.values))\n",
    "    print(\"-----------------------------------------------------------\")\n",
    "    print(\"NL:\", input_sentence)\n",
    "    print(\"FY:\", clean(daadwerkelijk))\n",
    "    print(\"AI:\", clean(decode_sequence(input_sentence)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meer opties\n",
    "|Probeersel         |Berendering                        |Effect\n",
    "|-                  |-                                  |-\n",
    "`warmup_steps` van 4000 naar 8000 te doen|Ik zag dat het model op stap 1 bijvoorbeeld een veel hogere gevalideerde accuraatheid had|De gevalideerde accuraatheid bleek een tikje lager hiermee.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'encoder_outputs' (of type TransformerEncoder) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "INFO:tensorflow:Converted call: <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x7efce0464360>\n",
      "    args: (<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7efce05d0390>,)\n",
      "    kwargs: {}\n",
      "\n",
      "INFO:tensorflow:Converted call: <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_data at 0x7efce04640e0>\n",
      "    args: (({'dutch': <tf.Tensor 'data:0' shape=(None, None) dtype=int64>, 'frisian': <tf.Tensor 'data_1:0' shape=(None, None) dtype=int64>}, <tf.Tensor 'data_2:0' shape=(None, None) dtype=int64>),)\n",
      "    kwargs: {}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/nn.py:609: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Converted call: <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_data at 0x7efce04640e0>\n",
      "    args: (({'dutch': <tf.Tensor 'data:0' shape=(None, None) dtype=int64>, 'frisian': <tf.Tensor 'data_1:0' shape=(None, None) dtype=int64>}, <tf.Tensor 'data_2:0' shape=(None, None) dtype=int64>),)\n",
      "    kwargs: {}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1728855973.292901   25118 assert_op.cc:38] Ignoring Assert operator compile_loss/masked_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1221/2174\u001b[0m \u001b[32mâââââââââââ\u001b[0m\u001b[37mâââââââââ\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 8.8266 - masked_accuracy: 0.0650"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1728855993.211105   25117 assert_op.cc:38] Ignoring Assert operator compile_loss/masked_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8.0465 - masked_accuracy: 0.1041INFO:tensorflow:Converted call: <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x7efcc0108720>\n",
      "    args: (<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7efce0273b90>,)\n",
      "    kwargs: {}\n",
      "\n",
      "INFO:tensorflow:Converted call: <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_data at 0x7efcc0108680>\n",
      "    args: (({'dutch': <tf.Tensor 'data:0' shape=(None, None) dtype=int64>, 'frisian': <tf.Tensor 'data_1:0' shape=(None, None) dtype=int64>}, <tf.Tensor 'data_2:0' shape=(None, None) dtype=int64>),)\n",
      "    kwargs: {}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1728856010.017144   25114 assert_op.cc:38] Ignoring Assert operator compile_loss/masked_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "W0000 00:00:1728856013.242195   25116 assert_op.cc:38] Ignoring Assert operator compile_loss/masked_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 17ms/step - loss: 8.0458 - masked_accuracy: 0.1042 - val_loss: 4.6477 - val_masked_accuracy: 0.3936\n",
      "Epoch 2/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 4.4175 - masked_accuracy: 0.4319 - val_loss: 3.3495 - val_masked_accuracy: 0.5549\n",
      "Epoch 3/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 3.4052 - masked_accuracy: 0.5591 - val_loss: 2.8081 - val_masked_accuracy: 0.6166\n",
      "Epoch 4/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 2.8682 - masked_accuracy: 0.6157 - val_loss: 2.4781 - val_masked_accuracy: 0.6615\n",
      "Epoch 5/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 2.4799 - masked_accuracy: 0.6636 - val_loss: 2.2712 - val_masked_accuracy: 0.6888\n",
      "Epoch 6/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 2.2383 - masked_accuracy: 0.6941 - val_loss: 2.1741 - val_masked_accuracy: 0.7017\n",
      "Epoch 7/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 2.0947 - masked_accuracy: 0.7110 - val_loss: 2.1248 - val_masked_accuracy: 0.7063\n",
      "Epoch 8/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 14ms/step - loss: 1.9925 - masked_accuracy: 0.7239 - val_loss: 2.0890 - val_masked_accuracy: 0.7125\n",
      "Epoch 9/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 1.9088 - masked_accuracy: 0.7343 - val_loss: 2.0636 - val_masked_accuracy: 0.7138\n",
      "Epoch 10/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 14ms/step - loss: 1.8444 - masked_accuracy: 0.7428 - val_loss: 2.0510 - val_masked_accuracy: 0.7158\n",
      "Epoch 11/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 14ms/step - loss: 1.7876 - masked_accuracy: 0.7505 - val_loss: 2.0441 - val_masked_accuracy: 0.7176\n",
      "Epoch 12/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 1.7389 - masked_accuracy: 0.7577 - val_loss: 2.0328 - val_masked_accuracy: 0.7190\n",
      "Epoch 13/30\n",
      "\u001b[1m 379/2174\u001b[0m \u001b[32mâââ\u001b[0m\u001b[37mâââââââââââââââââ\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - loss: 1.7054 - masked_accuracy: 0.7623"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 572/2174\u001b[0m \u001b[32mâââââ\u001b[0m\u001b[37mâââââââââââââââ\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - loss: 1.7040 - masked_accuracy: 0.7623"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "dense_dim = 1024\n",
    "num_heads = 8\n",
    "\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(dutch_maxlen,), dtype=\"int64\", name=\"dutch\")\n",
    "decoder_inputs = keras.Input(shape=(frisian_maxlen,), dtype=\"int64\", name=\"frisian\")\n",
    "\n",
    "# encoder_embedding = TokenAndPositionEmbedding(dutch_vocab_size, dutch_maxlen, embed_dim)(encoder_inputs)\n",
    "encoder_embedding = PositionalEmbedding(dutch_maxlen, dutch_vocab_size, embed_dim, name=\"encoder_embedding\")(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads, name=\"encoder_outputs\")(encoder_embedding)\n",
    "\n",
    "\n",
    "# decoder_embedding = TokenAndPositionEmbedding(frisian_vocab_size, frisian_maxlen, embed_dim)(decoder_inputs)\n",
    "decoder_embedding = PositionalEmbedding(frisian_maxlen, frisian_vocab_size, embed_dim, name=\"decoder_embedding\")(decoder_inputs)\n",
    "decoder = TransformerDecoder(embed_dim, dense_dim, num_heads, name=\"decoder\")(decoder_embedding, encoder_outputs)\n",
    "\n",
    "\n",
    "decoder_dropout = layers.Dropout(0.3, name=\"decoder_dropout\")(decoder)\n",
    "decoder_outputs = layers.Dense(frisian_vocab_size, activation=\"softmax\", name=\"decoder_outputs\")(decoder_dropout)\n",
    "\n",
    "\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "learning_rate = CustomSchedule(embed_dim)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)\n",
    "\n",
    "model.compile(\n",
    "    loss=masked_loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[masked_accuracy])\n",
    "\n",
    "history = model.fit(train_ds, epochs=30, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Tekst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tekst"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
