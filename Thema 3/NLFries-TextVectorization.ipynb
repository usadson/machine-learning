{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nederlands-Fries\n",
    "\n",
    "- https://leren.windesheim.nl/d2l/le/lessons/103162/topics/927096"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 1. Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vertaal Nederlandse zinnen naar het Fries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "School heeft ons al de code aangeleverd die een tekstcorpus van het Fryske Akademy downloadt, alsook deze gegevens omgezet naar een CSV-bestand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Bibliotheken importeren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_nlp in /usr/local/lib/python3.11/dist-packages (0.15.1)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras_nlp) (2.1.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras_nlp) (1.26.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras_nlp) (24.1)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from keras_nlp) (2024.9.11)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras_nlp) (13.7.1)\n",
      "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (from keras_nlp) (0.3.1)\n",
      "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.11/dist-packages (from keras_nlp) (2.17.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub->keras_nlp) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub->keras_nlp) (4.66.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras_nlp) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras_nlp) (2.18.0)\n",
      "Requirement already satisfied: tensorflow<2.18,>=2.17.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-text->keras_nlp) (2.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras_nlp) (0.1.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (4.25.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (70.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (2.17.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (3.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (0.37.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras_nlp) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras_nlp) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras_nlp) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras_nlp) (2024.7.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (0.43.0)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (0.0.8)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (0.12.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow-text->keras_nlp) (2.1.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install keras_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 11:27:19.391983: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-13 11:27:19.407004: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-13 11:27:19.410598: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-13 11:27:19.421376: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import keras\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras_nlp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"NederlandsFries.ipynb\" not in os.listdir('.'):\n",
    "    os.chdir(\"Thema 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Inlezen `dataset.csv`\n",
    "De corpus bevat twee simpele kolommen, een met de Nederlandse tekst, en een met de Friese vertaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 173912 entries, 0 to 173911\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   nederlands  173912 non-null  object\n",
      " 1   fries       173912 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nederlands</th>\n",
       "      <th>fries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we hebben de burgemeester het advies gegeven o...</td>\n",
       "      <td>wy hawwe de boargemaster it advys jun om it ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>we hebben de burgemeester het advies gegeven o...</td>\n",
       "      <td>wy hawwe de boargemaster it advys jun om it ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>een plotselinge dood</td>\n",
       "      <td>in hastige dea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>een plotselinge dood</td>\n",
       "      <td>in unferwachte dea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zijn plotseling overlijden</td>\n",
       "      <td>syn hastich ferstjerren</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          nederlands  \\\n",
       "0  we hebben de burgemeester het advies gegeven o...   \n",
       "1  we hebben de burgemeester het advies gegeven o...   \n",
       "2                               een plotselinge dood   \n",
       "3                               een plotselinge dood   \n",
       "4                         zijn plotseling overlijden   \n",
       "\n",
       "                                               fries  \n",
       "0  wy hawwe de boargemaster it advys jun om it ka...  \n",
       "1  wy hawwe de boargemaster it advys jun om it ka...  \n",
       "2                                     in hastige dea  \n",
       "3                                 in unferwachte dea  \n",
       "4                            syn hastich ferstjerren  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df = pd.read_csv(\"Data/dataset.csv\")\n",
    "dataset_df.info()\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Inzicht zinlengte\n",
    "We zien dat de teksten maximaal 60 woorden bevatten, en gemiddeld 9 woorden. Gelukkig niet te veel, zo kunnen we hem makkelijker trainen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min 1 Max 59 gemiddeld 9.066044896269378\n"
     ]
    }
   ],
   "source": [
    "hoeveelheid_woorden_nederlands = dataset_df['nederlands'].apply(lambda txt: len(txt.split()))\n",
    "print(f\"Min {hoeveelheid_woorden_nederlands.min()} Max {hoeveelheid_woorden_nederlands.max()} gemiddeld {hoeveelheid_woorden_nederlands.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min 1 Max 60 gemiddeld 9.237137172823036\n"
     ]
    }
   ],
   "source": [
    "hoeveelheid_woorden_fries = dataset_df['fries'].apply(lambda txt: len(txt.split()))\n",
    "print(f\"Min {hoeveelheid_woorden_fries.min()} Max {hoeveelheid_woorden_fries.max()} gemiddeld {hoeveelheid_woorden_fries.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Inzicht woordhoeveelheid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70245"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(np.hstack(dataset_df['nederlands'].apply(lambda txt: np.array(txt.split())))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74319"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(np.hstack(dataset_df['fries'].apply(lambda txt: np.array(txt.split())))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tekst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Start en eindtokens toevoegen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOKEN = \"[begin]\"\n",
    "END_TOKEN = \"[einde]\"\n",
    "\n",
    "def omringMetBeginEnEinde(tekst):\n",
    "    return f\"{START_TOKEN} {tekst} {END_TOKEN}\"\n",
    "\n",
    "dataset_df['fries'] = dataset_df['fries'].apply(omringMetBeginEnEinde)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Splitsen tussen traindata testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nederlands</th>\n",
       "      <th>fries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121580</th>\n",
       "      <td>dat het grote portret verloren is gegaan blijf...</td>\n",
       "      <td>[begin] dat it grutte portret teloar gien is b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125517</th>\n",
       "      <td>in het nest zaten nog drie ouderafhankelijke j...</td>\n",
       "      <td>[begin] yn it nest sieten noch trije alderofhi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96212</th>\n",
       "      <td>twee bij vijf drie bij vier centimeter</td>\n",
       "      <td>[begin] trije by fjouwer twa by fjouwer sintim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54420</th>\n",
       "      <td>samenwerken bij</td>\n",
       "      <td>[begin] oparbeidzje by [einde]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62721</th>\n",
       "      <td>op die vrijdagmorgen</td>\n",
       "      <td>[begin] op de freedtemoarn [einde]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               nederlands  \\\n",
       "121580  dat het grote portret verloren is gegaan blijf...   \n",
       "125517  in het nest zaten nog drie ouderafhankelijke j...   \n",
       "96212              twee bij vijf drie bij vier centimeter   \n",
       "54420                                     samenwerken bij   \n",
       "62721                                op die vrijdagmorgen   \n",
       "\n",
       "                                                    fries  \n",
       "121580  [begin] dat it grutte portret teloar gien is b...  \n",
       "125517  [begin] yn it nest sieten noch trije alderofhi...  \n",
       "96212   [begin] trije by fjouwer twa by fjouwer sintim...  \n",
       "54420                      [begin] oparbeidzje by [einde]  \n",
       "62721                  [begin] op de freedtemoarn [einde]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_dutch, test_dutch, train_frisian, test_frisian = train_test_split(\n",
    "#     dataset_df['nederlands'], dataset_df['fries'],\n",
    "#     test_size=0.2,\n",
    "#     shuffle = True,\n",
    "# )\n",
    "\n",
    "train_pairs, test_pairs = train_test_split(\n",
    "    dataset_df,\n",
    "    test_size=0.2,\n",
    "    shuffle = True,\n",
    ")\n",
    "\n",
    "train_pairs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Tekstvectorisatie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dutch_vocab_size   = 20000\n",
    "frisian_vocab_size = 20000\n",
    "\n",
    "dutch_maxlen   = 20\n",
    "frisian_maxlen = 20\n",
    "\n",
    "strip_chars = string.punctuation + \"Â¿\"\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728818845.540632   35572 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728818845.556282   35572 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728818845.556326   35572 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728818845.557753   35572 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728818845.557784   35572 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728818845.557802   35572 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728818845.665241   35572 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728818845.665292   35572 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-13 11:27:25.665303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1728818845.665340   35572 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-13 11:27:25.665364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5592 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:06:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dutch_text_vectorization = layers.TextVectorization(\n",
    "    max_tokens=dutch_vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=dutch_maxlen,\n",
    ")\n",
    "dutch_text_vectorization.adapt(dataset_df['nederlands'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "frisian_text_vectorization = layers.TextVectorization(\n",
    "    max_tokens=frisian_vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=frisian_maxlen + 1, # <--- om ervoor te zorgen dat hij de volgende gaat voorspellen\n",
    "    standardize=custom_standardization,\n",
    ")\n",
    "frisian_text_vectorization.adapt(dataset_df['fries'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "def format_dataset(dutch, frisian):\n",
    "    dutch = dutch_text_vectorization(dutch)\n",
    "    frisian = frisian_text_vectorization(frisian)\n",
    "\n",
    "    return ({\n",
    "        \"dutch\": dutch,\n",
    "        \"frisian\": frisian[:, :-1],\n",
    "    }, frisian[:, 1:])\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    dutch_texts = pairs['nederlands']\n",
    "    frisian_texts = pairs['fries']\n",
    "    dutch_texts = list(dutch_texts)\n",
    "    frisian_texts = list(frisian_texts)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dutch_texts, frisian_texts))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset, num_parallel_calls=16)\n",
    "    return dataset.shuffle(2048).prefetch(16).cache() #in memory caching ivm performance\n",
    "\n",
    "train_ds = make_dataset(train_pairs)\n",
    "test_ds = make_dataset(test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs['dutch'].shape: (64, 20)\n",
      "inputs['frisian'].shape: (64, 20)\n",
      "targets.shape: (64, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 11:27:27.571485: W tensorflow/core/kernels/data/cache_dataset_ops.cc:913] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 11:27:27.573666: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds.take(1):\n",
    "    print(f\"inputs['dutch'].shape: {inputs['dutch'].shape}\")\n",
    "    print(f\"inputs['frisian'].shape: {inputs['frisian'].shape}\")\n",
    "    print(f\"targets.shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'dutch': <tf.Tensor: shape=(64, 20), dtype=int64, numpy=\n",
      "array([[  254,  3237,    19, ...,     0,     0,     0],\n",
      "       [    2, 10077,     5, ...,     0,     0,     0],\n",
      "       [   24,     2,  2034, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [   26,    22,   575, ...,     0,     0,     0],\n",
      "       [   23,    50,  3496, ...,     1,     7,     2],\n",
      "       [   20,    38,  1486, ...,     0,     0,     0]])>, 'frisian': <tf.Tensor: shape=(64, 20), dtype=int64, numpy=\n",
      "array([[    3,   241,  3723, ...,     0,     0,     0],\n",
      "       [    3,     4, 10261, ...,     0,     0,     0],\n",
      "       [    3,    18,     4, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [    3,    26,    45, ...,     0,     0,     0],\n",
      "       [    3,    20,     7, ..., 16843,    25,    13],\n",
      "       [    3,    19,    44, ...,     0,     0,     0]])>}, <tf.Tensor: shape=(64, 20), dtype=int64, numpy=\n",
      "array([[  241,  3723,    22, ...,     0,     0,     0],\n",
      "       [    4, 10261,     7, ...,     0,     0,     0],\n",
      "       [   18,     4,  2295, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [   26,    45,   508, ...,     0,     0,     0],\n",
      "       [   20,     7,   196, ...,    25,    13,  2523],\n",
      "       [   19,    44,  1524, ...,     0,     0,     0]])>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 11:27:27.809272: W tensorflow/core/kernels/data/cache_dataset_ops.cc:913] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-10-13 11:27:27.811237: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for x in train_ds.take(1):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dutch   = tf.data.Dataset.from_tensor_slices(tf.cast(train_dutch.values, tf.string)).batch(64)\n",
    "# test_dutch    = tf.data.Dataset.from_tensor_slices(tf.cast(test_dutch.values, tf.string)).batch(64)\n",
    "# train_frisian = tf.data.Dataset.from_tensor_slices(tf.cast(train_frisian.values, tf.string)).batch(64)\n",
    "# test_frisian  = tf.data.Dataset.from_tensor_slices(tf.cast(test_frisian.values, tf.string)).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print([x for x in train_dutch.take(1)][0][0])\n",
    "# print([x for x in train_frisian.take(1)][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds = tf.data.Dataset.zip((train_dutch,train_frisian))\n",
    "# test_ds = tf.data.Dataset.zip((test_dutch,test_frisian))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int_train_ds = train_ds.map(\n",
    "#     lambda x, y: (dutch_text_vectorization(x), frisian_text_vectorization(y)),\n",
    "#     num_parallel_calls=16)\n",
    "\n",
    "# int_test_ds = test_ds.map(\n",
    "#     lambda x, y: (dutch_text_vectorization(x), frisian_text_vectorization(y)),\n",
    "#     num_parallel_calls=16)\n",
    "\n",
    "# print(np.array([x for x in int_train_ds.take(1)]).shape)\n",
    "# print(int_train_ds)\n",
    "# # print([x for x in int_test_ds.take(1)][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tekst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Initialize the embeddings for tokens and positions\n",
    "        self.token_embeddings = layers.Embedding(           # regular embedding\n",
    "            input_dim=input_dim, output_dim=output_dim)\n",
    "        self.position_embeddings = layers.Embedding(        # position embedding\n",
    "            input_dim=sequence_length, output_dim=output_dim)\n",
    "        # Some relevant settings for subsequent layers\n",
    "        # Definnig the settings as part of the object (self.) makes it\n",
    "        # easier to apply them consistently in the call() method\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]                               # Length of the input sentences\n",
    "        positions = tf.range(start=0, limit=length, delta=1)        # 0-indexed positions of tokens in the sequences\n",
    "        # Generate the actual position embeddings\n",
    "        embedded_tokens = self.token_embeddings(inputs)             # Regular embeddings of the tokens\n",
    "        embedded_positions = self.position_embeddings(positions)    # Position embeddings\n",
    "        # We maken hier een 2e embeddingspace voor de positie die we daarna bij het origineel optellen\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return keras.ops.not_equal(inputs, 0) #geneer mask basis van waar de input niet 0 is.Zodat we de input niet hoeven te padden\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"output_dim\": self.output_dim,\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "            \"input_dim\": self.input_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):                              # Our transformer encoder layer inherits from keras.layers.Layer\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):   # the constructor of our encoder layer\n",
    "        super().__init__(**kwargs)                                   # calls the constructor of the parent class (keras.layers.Layer)\n",
    "\n",
    "        # Store a whole bunch settings and initialise the building blocks for our encoder layer\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        # Multi-head attention building block\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        # Dense building block\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
    "             layers.Dense(embed_dim),]\n",
    "        )\n",
    "        # Layer normalisation building block, 1 and 2 are used to normalise the output of the attention and dense blocks respectively\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        # Here we actually build the encoder layer\n",
    "\n",
    "        # If we define a mask for attention, we need to perform some preprocessing on it\n",
    "        if mask is not None:\n",
    "            mask = mask[:, tf.newaxis, :] #padding mask (negeer alle paffing) voeg een dimensie toe. Transformer verwacht 3D of meer. Embedding layer genereerd 2d layer\n",
    "\n",
    "        # Define the attention part of the encoder\n",
    "        attention_output = self.attention(\n",
    "            inputs, inputs, attention_mask=mask)\n",
    "        # Apply layer normalisation to the attention output\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        # Apply the dense part of the encoder\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        # Apply layer normalisation to the dense output, and return the encoder\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "    def get_config(self):\n",
    "        # Return all the configuration settings for this layer\n",
    "\n",
    "        # Get the configuration settings from the parent class\n",
    "        config = super().get_config()\n",
    "        # Add the config settings of our own layer\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.attention_2 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
    "             layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "        self.supports_masking = True #anders geen masking mogelijk\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        #prevents the model from learning to copy the next token from the input to the output by hiden it\n",
    "        # [[1,0,0],\n",
    "        #  [1,1,0],\n",
    "        #  [1,1,1]]\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1),\n",
    "             tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
    "        #Replicate it along the batch axis to get an matrix of shape (batch_size, sequence_length, sequence_length)\n",
    "        return tf.tile(mask, mult)\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "        #retrieve the casual mask\n",
    "        padding_mask = None\n",
    "        if mask is not None: #prepare the input mask that describes padding locations in the target_sequence\n",
    "            padding_mask = keras.cast(\n",
    "                mask[:, tf.newaxis, :], dtype=\"int32\") #extra dim aangezien transfo deze verwacht\n",
    "            padding_mask = keras.minimum(padding_mask, causal_mask)#merge both masks (input padding en volgende woord padding)\n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=inputs,\n",
    "            value=inputs,\n",
    "            key=inputs,\n",
    "            attention_mask=causal_mask)# pass the casual mask tot the first attention layer, which performs self attention over the target sequence\n",
    "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "        attention_output_2 = self.attention_2(\n",
    "            query=attention_output_1,\n",
    "            value=encoder_outputs,\n",
    "            key=encoder_outputs,\n",
    "            attention_mask=padding_mask, #pass the combined mask to the second attention layer, which relates the source sequence to the target sequence\n",
    "        )\n",
    "        attention_output_2 = self.layernorm_2(\n",
    "            attention_output_1 + attention_output_2)\n",
    "        proj_output = self.dense_proj(attention_output_2)\n",
    "        return self.layernorm_3(attention_output_2 + proj_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.framework.ops import disable_eager_execution\n",
    "# disable_eager_execution()\n",
    "\n",
    "# import tensorflow.compat.v1 as tf\n",
    "# tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "embed_dim = 64\n",
    "dense_dim = 1024\n",
    "num_heads = 8\n",
    "\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(dutch_maxlen,), dtype=\"int64\", name=\"dutch\")\n",
    "decoder_inputs = keras.Input(shape=(frisian_maxlen,), dtype=\"int64\", name=\"frisian\")\n",
    "\n",
    "# encoder_embedding = TokenAndPositionEmbedding(dutch_vocab_size, dutch_maxlen, embed_dim)(encoder_inputs)\n",
    "encoder_embedding = PositionalEmbedding(dutch_maxlen, dutch_vocab_size, embed_dim, name=\"encoder_embedding\")(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads, name=\"encoder_outputs\")(encoder_embedding)\n",
    "\n",
    "\n",
    "# decoder_embedding = TokenAndPositionEmbedding(frisian_vocab_size, frisian_maxlen, embed_dim)(decoder_inputs)\n",
    "decoder_embedding = PositionalEmbedding(frisian_maxlen, frisian_vocab_size, embed_dim, name=\"decoder_embedding\")(decoder_inputs)\n",
    "decoder = TransformerDecoder(embed_dim, dense_dim, num_heads, name=\"decoder\")(decoder_embedding, encoder_outputs)\n",
    "\n",
    "\n",
    "decoder_dropout = layers.Dropout(0.5, name=\"decoder_dropout\")(decoder)\n",
    "decoder_outputs = layers.Dense(frisian_vocab_size, activation=\"softmax\", name=\"decoder_outputs\")(decoder_dropout)\n",
    "\n",
    "\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ter [ts](/usr/local/lib/python3.11/dist-packages/keras_nlp/src/layers/modeling/transformer_encoder.py)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.AdamW(5e-5),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    jit_compile=True,\n",
    ")\n",
    "history = model.fit(train_ds, epochs=3, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "acc=history.history['sparse_categorical_accuracy']\n",
    "val_acc=history.history['val_sparse_categorical_accuracy']\n",
    "epochs=range(1, len(acc)+1)\n",
    "plt.plot(epochs, acc, label='accuracy')\n",
    "plt.plot(epochs, val_acc, label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, ziet er veelbelovend uit! Nu snel maar eens een aantal extra keer bijtrainen:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "embed_dim = 64\n",
    "dense_dim = 1024\n",
    "num_heads = 8\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(dutch_maxlen,), dtype=\"int64\", name=\"dutch\")\n",
    "decoder_inputs = keras.Input(shape=(frisian_maxlen,), dtype=\"int64\", name=\"frisian\")\n",
    "encoder_embedding = PositionalEmbedding(dutch_maxlen, dutch_vocab_size, embed_dim, name=\"encoder_embedding\")(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads, name=\"encoder_outputs\")(encoder_embedding)\n",
    "decoder_embedding = PositionalEmbedding(frisian_maxlen, frisian_vocab_size, embed_dim, name=\"decoder_embedding\")(decoder_inputs)\n",
    "decoder = TransformerDecoder(embed_dim, dense_dim, num_heads, name=\"decoder\")(decoder_embedding, encoder_outputs)\n",
    "decoder_dropout = layers.Dropout(0.5, name=\"decoder_dropout\")(decoder)\n",
    "decoder_outputs = layers.Dense(frisian_vocab_size, activation=\"softmax\", name=\"decoder_outputs\")(decoder_dropout)\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# model.compile(\n",
    "#     loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#     optimizer=keras.optimizers.Adam(5e-5),\n",
    "#     metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "#     jit_compile=True,\n",
    "# )\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    "    jit_compile=True)\n",
    "history = model.fit(train_ds, epochs=30, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.x Meer params"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "embed_dim = 256\n",
    "dense_dim = 2024\n",
    "num_heads = 8\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(dutch_maxlen,), dtype=\"int64\", name=\"dutch\")\n",
    "decoder_inputs = keras.Input(shape=(frisian_maxlen,), dtype=\"int64\", name=\"frisian\")\n",
    "encoder_embedding = PositionalEmbedding(dutch_maxlen, dutch_vocab_size, embed_dim, name=\"encoder_embedding\")(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads, name=\"encoder_outputs\")(encoder_embedding)\n",
    "decoder_embedding = PositionalEmbedding(frisian_maxlen, frisian_vocab_size, embed_dim, name=\"decoder_embedding\")(decoder_inputs)\n",
    "decoder = TransformerDecoder(embed_dim, dense_dim, num_heads, name=\"decoder\")(decoder_embedding, encoder_outputs)\n",
    "decoder_dropout = layers.Dropout(0.5, name=\"decoder_dropout\")(decoder)\n",
    "decoder_outputs = layers.Dense(frisian_vocab_size, activation=\"softmax\", name=\"decoder_outputs\")(decoder_dropout)\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    "    # jit_compile=True\n",
    "    )\n",
    "history = model.fit(train_ds, epochs=30, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.x. Lagere dropout\n",
    "Gezien overfitting geen probleem is op het moment, probeer ik hem te verlagen."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "embed_dim = 256\n",
    "dense_dim = 2024\n",
    "num_heads = 8\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(dutch_maxlen,), dtype=\"int64\", name=\"dutch\")\n",
    "decoder_inputs = keras.Input(shape=(frisian_maxlen,), dtype=\"int64\", name=\"frisian\")\n",
    "encoder_embedding = PositionalEmbedding(dutch_maxlen, dutch_vocab_size, embed_dim, name=\"encoder_embedding\")(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads, name=\"encoder_outputs\")(encoder_embedding)\n",
    "decoder_embedding = PositionalEmbedding(frisian_maxlen, frisian_vocab_size, embed_dim, name=\"decoder_embedding\")(decoder_inputs)\n",
    "decoder = TransformerDecoder(embed_dim, dense_dim, num_heads, name=\"decoder\")(decoder_embedding, encoder_outputs)\n",
    "decoder_dropout = layers.Dropout(0.1, name=\"decoder_dropout\")(decoder)\n",
    "decoder_outputs = layers.Dense(frisian_vocab_size, activation=\"softmax\", name=\"decoder_outputs\")(decoder_dropout)\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]    )\n",
    "history = model.fit(train_ds, epochs=5, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "acc=history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "epochs=range(1, len(acc)+1)\n",
    "plt.plot(epochs, acc, label='accuracy')\n",
    "plt.plot(epochs, val_acc, label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.x. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "embed_dim = 256\n",
    "dense_dim = 2024\n",
    "num_heads = 8\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(dutch_maxlen,), dtype=\"int64\", name=\"dutch\")\n",
    "encoder_embedding = PositionalEmbedding(dutch_maxlen, dutch_vocab_size, embed_dim, name=\"encoder_embedding\")(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads, name=\"encoder_outputs\")(encoder_embedding)\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(frisian_maxlen,), dtype=\"int64\", name=\"frisian\")\n",
    "decoder_embedding = PositionalEmbedding(frisian_maxlen, frisian_vocab_size, embed_dim, name=\"decoder_embedding\")(decoder_inputs)\n",
    "decoder = TransformerDecoder(embed_dim, dense_dim, num_heads, name=\"decoder\")(decoder_embedding, encoder_outputs)\n",
    "decoder_dropout = layers.Dropout(0.5, name=\"decoder_dropout\")(decoder)\n",
    "decoder_outputs = layers.Dense(frisian_vocab_size, activation=\"softmax\", name=\"decoder_outputs\")(decoder_dropout)\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]    )\n",
    "history = model.fit(train_ds, epochs=30, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#nog even testen\n",
    "import numpy as np\n",
    "import random\n",
    "fy_vocab = frisian_text_vectorization.get_vocabulary()\n",
    "fy_index_lookup = dict(zip(range(len(fy_vocab)), fy_vocab))\n",
    "max_decoded_sentence_length = 20\n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = dutch_text_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = frisian_text_vectorization(\n",
    "            [decoded_sentence])\n",
    "        predictions = model(\n",
    "            [tokenized_input_sentence, tokenized_target_sentence])\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = fy_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence\n",
    "\n",
    "test_dutch_texts = [pair[0] for pair in test_pairs]\n",
    "for _ in range(20):\n",
    "    input_sentence = random.choice(test_dutch_texts)\n",
    "    print(\"-\")\n",
    "    print(input_sentence)\n",
    "    print(decode_sequence(input_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZONDAG"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "embed_dim = 512\n",
    "dense_dim = 1024\n",
    "num_heads = 8\n",
    "\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(dutch_maxlen,), dtype=\"int64\", name=\"dutch\")\n",
    "decoder_inputs = keras.Input(shape=(frisian_maxlen,), dtype=\"int64\", name=\"frisian\")\n",
    "\n",
    "# encoder_embedding = TokenAndPositionEmbedding(dutch_vocab_size, dutch_maxlen, embed_dim)(encoder_inputs)\n",
    "encoder_embedding = PositionalEmbedding(dutch_maxlen, dutch_vocab_size, embed_dim, name=\"encoder_embedding\")(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads, name=\"encoder_outputs\")(encoder_embedding)\n",
    "\n",
    "\n",
    "# decoder_embedding = TokenAndPositionEmbedding(frisian_vocab_size, frisian_maxlen, embed_dim)(decoder_inputs)\n",
    "decoder_embedding = PositionalEmbedding(frisian_maxlen, frisian_vocab_size, embed_dim, name=\"decoder_embedding\")(decoder_inputs)\n",
    "decoder = TransformerDecoder(embed_dim, dense_dim, num_heads, name=\"decoder\")(decoder_embedding, encoder_outputs)\n",
    "\n",
    "\n",
    "decoder_dropout = layers.Dropout(0.5, name=\"decoder_dropout\")(decoder)\n",
    "decoder_outputs = layers.Dense(frisian_vocab_size, activation=\"softmax\", name=\"decoder_outputs\")(decoder_dropout)\n",
    "\n",
    "\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# model.compile(\n",
    "#     loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#     optimizer=keras.optimizers.AdamW(5e-5),\n",
    "#     metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "#     jit_compile=True,\n",
    "# )\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "history = model.fit(train_ds, epochs=3, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MASKED LOSS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "embed_dim = 128\n",
    "dense_dim = 1024\n",
    "num_heads = 8\n",
    "\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(dutch_maxlen,), dtype=\"int64\", name=\"dutch\")\n",
    "decoder_inputs = keras.Input(shape=(frisian_maxlen,), dtype=\"int64\", name=\"frisian\")\n",
    "\n",
    "# encoder_embedding = TokenAndPositionEmbedding(dutch_vocab_size, dutch_maxlen, embed_dim)(encoder_inputs)\n",
    "encoder_embedding = PositionalEmbedding(dutch_maxlen, dutch_vocab_size, embed_dim, name=\"encoder_embedding\")(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads, name=\"encoder_outputs\")(encoder_embedding)\n",
    "\n",
    "\n",
    "# decoder_embedding = TokenAndPositionEmbedding(frisian_vocab_size, frisian_maxlen, embed_dim)(decoder_inputs)\n",
    "decoder_embedding = PositionalEmbedding(frisian_maxlen, frisian_vocab_size, embed_dim, name=\"decoder_embedding\")(decoder_inputs)\n",
    "decoder = TransformerDecoder(embed_dim, dense_dim, num_heads, name=\"decoder\")(decoder_embedding, encoder_outputs)\n",
    "\n",
    "\n",
    "decoder_dropout = layers.Dropout(0.5, name=\"decoder_dropout\")(decoder)\n",
    "decoder_outputs = layers.Dense(frisian_vocab_size, activation=\"softmax\", name=\"decoder_outputs\")(decoder_dropout)\n",
    "\n",
    "\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss(label, pred):\n",
    "  mask = label != 0\n",
    "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "  loss = loss_object(label, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss.dtype)\n",
    "  loss *= mask\n",
    "\n",
    "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "  return loss\n",
    "\n",
    "\n",
    "def masked_accuracy(label, pred):\n",
    "  pred = tf.argmax(pred, axis=2)\n",
    "  label = tf.cast(label, pred.dtype)\n",
    "  match = label == pred\n",
    "\n",
    "  mask = label != 0\n",
    "\n",
    "  match = match & mask\n",
    "\n",
    "  match = tf.cast(match, dtype=tf.float32)\n",
    "  mask = tf.cast(mask, dtype=tf.float32)\n",
    "  return tf.reduce_sum(match)/tf.reduce_sum(mask)\n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    step = tf.cast(step, dtype=tf.float32)\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n",
    "\n",
    "learning_rate = CustomSchedule(embed_dim)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)\n",
    "\n",
    "model.compile(\n",
    "    loss=masked_loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[masked_accuracy])\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "history = model.fit(train_ds, epochs=3, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#nog even testen\n",
    "import numpy as np\n",
    "import random\n",
    "fy_vocab = frisian_text_vectorization.get_vocabulary()\n",
    "fy_index_lookup = dict(zip(range(len(fy_vocab)), fy_vocab))\n",
    "max_decoded_sentence_length = 20\n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = dutch_text_vectorization([input_sentence])\n",
    "    decoded_sentence = START_TOKEN\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = frisian_text_vectorization(\n",
    "            [decoded_sentence])\n",
    "        predictions = model(\n",
    "            [tokenized_input_sentence, tokenized_target_sentence])\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = fy_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token + str(sampled_token_index)\n",
    "        if sampled_token == END_TOKEN:\n",
    "            break\n",
    "    return decoded_sentence\n",
    "\n",
    "test_dutch_texts = [pair[0] for pair in test_pairs]\n",
    "for _ in range(20):\n",
    "    input_sentence = random.choice(test_dutch_texts)\n",
    "    print(\"-\")\n",
    "    print(input_sentence)\n",
    "    print(decode_sequence(input_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'encoder_outputs' (of type TransformerEncoder) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âââââââââââââââââââââââ³ââââââââââââââââââââ³âââââââââââââ³ââââââââââââââââââââ\n",
       "â<span style=\"font-weight: bold\"> Layer (type)        </span>â<span style=\"font-weight: bold\"> Output Shape      </span>â<span style=\"font-weight: bold\">    Param # </span>â<span style=\"font-weight: bold\"> Connected to      </span>â\n",
       "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
       "â dutch (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â -                 â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â frisian             â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â -                 â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â                   â            â                   â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â encoder_embedding   â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   â  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,562,560</span> â dutch[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddiâ¦</span> â                   â            â                   â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â not_equal           â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â dutch[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          â                   â            â                   â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â decoder_embedding   â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   â  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,562,560</span> â frisian[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddiâ¦</span> â                   â            â                   â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â encoder_outputs     â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   â    <span style=\"color: #00af00; text-decoration-color: #00af00\">791,296</span> â encoder_embeddinâ¦ â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncodeâ¦</span> â                   â            â not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â decoder             â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   â  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,319,040</span> â decoder_embeddinâ¦ â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecodeâ¦</span> â                   â            â encoder_outputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">â¦</span> â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â decoder_dropout     â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â decoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â                   â            â                   â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â decoder_outputs     â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20000</span>) â  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,580,000</span> â decoder_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">â¦</span> â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â                   â            â                   â\n",
       "âââââââââââââââââââââââ´ââââââââââââââââââââ´âââââââââââââ´ââââââââââââââââââââ\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âââââââââââââââââââââââ³ââââââââââââââââââââ³âââââââââââââ³ââââââââââââââââââââ\n",
       "â\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ\n",
       "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
       "â dutch (\u001b[38;5;33mInputLayer\u001b[0m)  â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        â          \u001b[38;5;34m0\u001b[0m â -                 â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â frisian             â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        â          \u001b[38;5;34m0\u001b[0m â -                 â\n",
       "â (\u001b[38;5;33mInputLayer\u001b[0m)        â                   â            â                   â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â encoder_embedding   â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)   â  \u001b[38;5;34m2,562,560\u001b[0m â dutch[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â\n",
       "â (\u001b[38;5;33mPositionalEmbeddiâ¦\u001b[0m â                   â            â                   â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â not_equal           â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        â          \u001b[38;5;34m0\u001b[0m â dutch[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â\n",
       "â (\u001b[38;5;33mNotEqual\u001b[0m)          â                   â            â                   â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â decoder_embedding   â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)   â  \u001b[38;5;34m2,562,560\u001b[0m â frisian[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â\n",
       "â (\u001b[38;5;33mPositionalEmbeddiâ¦\u001b[0m â                   â            â                   â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â encoder_outputs     â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)   â    \u001b[38;5;34m791,296\u001b[0m â encoder_embeddinâ¦ â\n",
       "â (\u001b[38;5;33mTransformerEncodeâ¦\u001b[0m â                   â            â not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â decoder             â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)   â  \u001b[38;5;34m1,319,040\u001b[0m â decoder_embeddinâ¦ â\n",
       "â (\u001b[38;5;33mTransformerDecodeâ¦\u001b[0m â                   â            â encoder_outputs[\u001b[38;5;34mâ¦\u001b[0m â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â decoder_dropout     â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)   â          \u001b[38;5;34m0\u001b[0m â decoder[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â\n",
       "â (\u001b[38;5;33mDropout\u001b[0m)           â                   â            â                   â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â decoder_outputs     â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20000\u001b[0m) â  \u001b[38;5;34m2,580,000\u001b[0m â decoder_dropout[\u001b[38;5;34mâ¦\u001b[0m â\n",
       "â (\u001b[38;5;33mDense\u001b[0m)             â                   â            â                   â\n",
       "âââââââââââââââââââââââ´ââââââââââââââââââââ´âââââââââââââ´ââââââââââââââââââââ\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,815,456</span> (37.44 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,815,456\u001b[0m (37.44 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,815,456</span> (37.44 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,815,456\u001b[0m (37.44 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "dense_dim = 1024\n",
    "num_heads = 8\n",
    "\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(dutch_maxlen,), dtype=\"int64\", name=\"dutch\")\n",
    "decoder_inputs = keras.Input(shape=(frisian_maxlen,), dtype=\"int64\", name=\"frisian\")\n",
    "\n",
    "# encoder_embedding = TokenAndPositionEmbedding(dutch_vocab_size, dutch_maxlen, embed_dim)(encoder_inputs)\n",
    "encoder_embedding = PositionalEmbedding(dutch_maxlen, dutch_vocab_size, embed_dim, name=\"encoder_embedding\")(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads, name=\"encoder_outputs\")(encoder_embedding)\n",
    "\n",
    "\n",
    "# decoder_embedding = TokenAndPositionEmbedding(frisian_vocab_size, frisian_maxlen, embed_dim)(decoder_inputs)\n",
    "decoder_embedding = PositionalEmbedding(frisian_maxlen, frisian_vocab_size, embed_dim, name=\"decoder_embedding\")(decoder_inputs)\n",
    "decoder = TransformerDecoder(embed_dim, dense_dim, num_heads, name=\"decoder\")(decoder_embedding, encoder_outputs)\n",
    "\n",
    "\n",
    "decoder_dropout = layers.Dropout(0.5, name=\"decoder_dropout\")(decoder)\n",
    "decoder_outputs = layers.Dense(frisian_vocab_size, activation=\"softmax\", name=\"decoder_outputs\")(decoder_dropout)\n",
    "\n",
    "\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/nn.py:609: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728818853.210560   35696 service.cc:146] XLA service 0x7f149c00adf0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1728818853.210611   35696 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Ti, Compute Capability 8.6\n",
      "2024-10-13 11:27:33.319850: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "W0000 00:00:1728818853.546035   35696 assert_op.cc:38] Ignoring Assert operator compile_loss/masked_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "2024-10-13 11:27:33.849788: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8906\n",
      "2024-10-13 11:27:36.813010: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_82', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-10-13 11:27:36.935015: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_10', 132 bytes spill stores, 132 bytes spill loads\n",
      "\n",
      "2024-10-13 11:27:37.321494: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_82', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-10-13 11:27:37.371305: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_84', 316 bytes spill stores, 316 bytes spill loads\n",
      "\n",
      "2024-10-13 11:27:37.399804: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_10', 1444 bytes spill stores, 1784 bytes spill loads\n",
      "\n",
      "2024-10-13 11:27:37.812012: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_84', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-10-13 11:27:37.983925: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_84', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-10-13 11:27:38.007921: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_82', 1784 bytes spill stores, 2144 bytes spill loads\n",
      "\n",
      "2024-10-13 11:27:38.182867: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_41', 1488 bytes spill stores, 1920 bytes spill loads\n",
      "\n",
      "2024-10-13 11:27:38.384229: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_10', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-10-13 11:27:38.965258: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_60', 148 bytes spill stores, 148 bytes spill loads\n",
      "\n",
      "2024-10-13 11:27:39.111405: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_84', 1796 bytes spill stores, 2156 bytes spill loads\n",
      "\n",
      "2024-10-13 11:27:39.336801: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_60', 212 bytes spill stores, 200 bytes spill loads\n",
      "\n",
      "2024-10-13 11:27:39.961930: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_82', 316 bytes spill stores, 316 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   1/2174\u001b[0m \u001b[37mââââââââââââââââââââ\u001b[0m \u001b[1m9:26:33\u001b[0m 16s/step - loss: 9.9163 - masked_accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1728818864.295554   35696 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2078/2174\u001b[0m \u001b[32mâââââââââââââââââââ\u001b[0m\u001b[37mâ\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 7.3588 - masked_accuracy: 0.1483"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1728818889.558124   35693 assert_op.cc:38] Ignoring Assert operator compile_loss/masked_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "2024-10-13 11:28:10.299962: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_76', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-10-13 11:28:11.098543: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_10', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2024-10-13 11:28:11.154019: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_76', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2024-10-13 11:28:11.162926: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_76', 192 bytes spill stores, 164 bytes spill loads\n",
      "\n",
      "2024-10-13 11:28:11.204987: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_10', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "2024-10-13 11:28:12.448507: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_10', 600 bytes spill stores, 404 bytes spill loads\n",
      "\n",
      "2024-10-13 11:28:12.511491: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_83', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2024-10-13 11:28:12.585396: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_83', 192 bytes spill stores, 164 bytes spill loads\n",
      "\n",
      "2024-10-13 11:28:12.724556: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_84', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-10-13 11:28:13.034258: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_10', 200 bytes spill stores, 200 bytes spill loads\n",
      "\n",
      "2024-10-13 11:28:13.452122: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_41', 1488 bytes spill stores, 1920 bytes spill loads\n",
      "\n",
      "2024-10-13 11:28:13.915065: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_82', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-10-13 11:28:14.018687: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_60', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "2024-10-13 11:28:14.623827: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_10', 712 bytes spill stores, 880 bytes spill loads\n",
      "\n",
      "2024-10-13 11:28:14.655703: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_82', 348 bytes spill stores, 348 bytes spill loads\n",
      "\n",
      "2024-10-13 11:28:14.805196: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_83', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-10-13 11:28:15.157883: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_84', 348 bytes spill stores, 348 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2170/2174\u001b[0m \u001b[32mâââââââââââââââââââ\u001b[0m\u001b[37mâ\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.2924 - masked_accuracy: 0.1539"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1728818901.220894   35693 assert_op.cc:38] Ignoring Assert operator compile_loss/masked_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "W0000 00:00:1728818904.011991   35693 assert_op.cc:38] Ignoring Assert operator compile_loss/masked_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "2024-10-13 11:28:24.334875: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_21', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-10-13 11:28:25.357309: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_21', 192 bytes spill stores, 164 bytes spill loads\n",
      "\n",
      "2024-10-13 11:28:25.428822: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_21', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2024-10-13 11:28:25.495985: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_10', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "2024-10-13 11:28:25.659926: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_10', 80 bytes spill stores, 80 bytes spill loads\n",
      "\n",
      "2024-10-13 11:28:25.707068: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_24', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-10-13 11:28:25.781545: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_10', 600 bytes spill stores, 404 bytes spill loads\n",
      "\n",
      "2024-10-13 11:28:25.984094: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_10', 200 bytes spill stores, 200 bytes spill loads\n",
      "\n",
      "2024-10-13 11:28:26.106121: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_24', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2024-10-13 11:28:26.296975: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_10', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 21ms/step - loss: 7.2888 - masked_accuracy: 0.1542 - val_loss: 3.8055 - val_masked_accuracy: 0.5009\n",
      "Epoch 2/3\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 3.7648 - masked_accuracy: 0.5181 - val_loss: 2.7605 - val_masked_accuracy: 0.6316\n",
      "Epoch 3/3\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 2.7744 - masked_accuracy: 0.6320 - val_loss: 2.3537 - val_masked_accuracy: 0.6816\n"
     ]
    }
   ],
   "source": [
    "learning_rate = CustomSchedule(embed_dim)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)\n",
    "\n",
    "model.compile(\n",
    "    loss=masked_loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[masked_accuracy])\n",
    "\n",
    "history = model.fit(train_ds, epochs=3, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "NL: ik kan wel zingen maar tekstschrijven dat is eigenlijk niet zozeer mijn ding\n",
      "FY: [begin] ik kin wol sjongen mar it is eins net echt dat is dat is [einde]\n",
      "-----------------------------------------------------------\n",
      "NL: was ik er maar nooit aan begonnen dacht ik al snel levensgevaarlijk zon onlinediscussie\n",
      "FY: [begin] wie ik der mar nea oan begun tocht ik al gau [UNK] [einde]\n",
      "-----------------------------------------------------------\n",
      "NL: vooral door kennis van de markt ontstaan kansen en kunnen kansen worden uitgebuit om onderhoudsbaggerwerk zo efficient mogelijk uit te voeren\n",
      "FY: [begin] foaral troch kennis fan e merk untstean kansen en kinne kansen en kinne derom [UNK] om [UNK] sa hiel te\n",
      "-----------------------------------------------------------\n",
      "NL: als kind al werd de levertraan bestreden met sinaasappel zo bestrijd je vervelende zaken met een roze bril\n",
      "FY: [begin] as bern al waard de [UNK] [UNK] mei [UNK] mei [UNK] dyn ferfelende saken mei in roze bril [einde]\n",
      "-----------------------------------------------------------\n",
      "NL: scheer je weg\n",
      "FY: [begin] [UNK] [einde]\n"
     ]
    }
   ],
   "source": [
    "#nog even testen\n",
    "import numpy as np\n",
    "import random\n",
    "fy_vocab = frisian_text_vectorization.get_vocabulary()\n",
    "fy_index_lookup = dict(zip(range(len(fy_vocab)), fy_vocab))\n",
    "max_decoded_sentence_length = 20\n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = dutch_text_vectorization([input_sentence])\n",
    "    decoded_sentence = START_TOKEN\n",
    "    indices = []\n",
    "\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence: tf.Tensor = frisian_text_vectorization([decoded_sentence])\n",
    "        tokenized_target_sentence = tokenized_target_sentence[:, :-1]\n",
    "        predictions = model([tokenized_input_sentence, tokenized_target_sentence])\n",
    "\n",
    "        # Pak altijd de laatste voorspelling\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        indices.append(sampled_token_index)\n",
    "\n",
    "        sampled_token = fy_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "\n",
    "        if sampled_token == END_TOKEN:\n",
    "            break\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "test_dutch_texts = [pair[0] for pair in test_pairs.values]\n",
    "for _ in range(5):\n",
    "    input_sentence = random.choice(test_dutch_texts)\n",
    "    print(\"-----------------------------------------------------------\")\n",
    "    print(\"NL:\", input_sentence)\n",
    "    print(\"FY:\", decode_sequence(input_sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âââââââââââââââââââââââ³ââââââââââââââââââââ³âââââââââââââ³ââââââââââââââââââââ\n",
       "â<span style=\"font-weight: bold\"> Layer (type)        </span>â<span style=\"font-weight: bold\"> Output Shape      </span>â<span style=\"font-weight: bold\">    Param # </span>â<span style=\"font-weight: bold\"> Connected to      </span>â\n",
       "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
       "â dutch (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â -                 â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â frisian             â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â -                 â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â                   â            â                   â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â encoder_embedding   â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   â  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,562,560</span> â dutch[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddiâ¦</span> â                   â            â                   â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â not_equal_2         â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â dutch[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          â                   â            â                   â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â decoder_embedding   â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   â  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,562,560</span> â frisian[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddiâ¦</span> â                   â            â                   â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â encoder_outputs     â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   â    <span style=\"color: #00af00; text-decoration-color: #00af00\">791,296</span> â encoder_embeddinâ¦ â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncodeâ¦</span> â                   â            â not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â decoder             â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   â  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,319,040</span> â decoder_embeddinâ¦ â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecodeâ¦</span> â                   â            â encoder_outputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">â¦</span> â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â decoder_dropout     â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â decoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â                   â            â                   â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â decoder_outputs     â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20000</span>) â  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,580,000</span> â decoder_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">â¦</span> â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â                   â            â                   â\n",
       "âââââââââââââââââââââââ´ââââââââââââââââââââ´âââââââââââââ´ââââââââââââââââââââ\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âââââââââââââââââââââââ³ââââââââââââââââââââ³âââââââââââââ³ââââââââââââââââââââ\n",
       "â\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ\n",
       "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
       "â dutch (\u001b[38;5;33mInputLayer\u001b[0m)  â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        â          \u001b[38;5;34m0\u001b[0m â -                 â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â frisian             â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        â          \u001b[38;5;34m0\u001b[0m â -                 â\n",
       "â (\u001b[38;5;33mInputLayer\u001b[0m)        â                   â            â                   â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â encoder_embedding   â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)   â  \u001b[38;5;34m2,562,560\u001b[0m â dutch[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â\n",
       "â (\u001b[38;5;33mPositionalEmbeddiâ¦\u001b[0m â                   â            â                   â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â not_equal_2         â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        â          \u001b[38;5;34m0\u001b[0m â dutch[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â\n",
       "â (\u001b[38;5;33mNotEqual\u001b[0m)          â                   â            â                   â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â decoder_embedding   â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)   â  \u001b[38;5;34m2,562,560\u001b[0m â frisian[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â\n",
       "â (\u001b[38;5;33mPositionalEmbeddiâ¦\u001b[0m â                   â            â                   â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â encoder_outputs     â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)   â    \u001b[38;5;34m791,296\u001b[0m â encoder_embeddinâ¦ â\n",
       "â (\u001b[38;5;33mTransformerEncodeâ¦\u001b[0m â                   â            â not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â decoder             â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)   â  \u001b[38;5;34m1,319,040\u001b[0m â decoder_embeddinâ¦ â\n",
       "â (\u001b[38;5;33mTransformerDecodeâ¦\u001b[0m â                   â            â encoder_outputs[\u001b[38;5;34mâ¦\u001b[0m â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â decoder_dropout     â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)   â          \u001b[38;5;34m0\u001b[0m â decoder[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â\n",
       "â (\u001b[38;5;33mDropout\u001b[0m)           â                   â            â                   â\n",
       "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
       "â decoder_outputs     â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20000\u001b[0m) â  \u001b[38;5;34m2,580,000\u001b[0m â decoder_dropout[\u001b[38;5;34mâ¦\u001b[0m â\n",
       "â (\u001b[38;5;33mDense\u001b[0m)             â                   â            â                   â\n",
       "âââââââââââââââââââââââ´ââââââââââââââââââââ´âââââââââââââ´ââââââââââââââââââââ\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,815,456</span> (37.44 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,815,456\u001b[0m (37.44 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,815,456</span> (37.44 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,815,456\u001b[0m (37.44 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/nn.py:609: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n",
      "W0000 00:00:1728819666.829677   35696 assert_op.cc:38] Ignoring Assert operator compile_loss/masked_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2076/2174\u001b[0m \u001b[32mâââââââââââââââââââ\u001b[0m\u001b[37mâ\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 7.3514 - masked_accuracy: 0.1480"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1728819695.888767   35694 assert_op.cc:38] Ignoring Assert operator compile_loss/masked_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2173/2174\u001b[0m \u001b[32mâââââââââââââââââââ\u001b[0m\u001b[37mâ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 7.2817 - masked_accuracy: 0.1538"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1728819701.273051   35697 assert_op.cc:38] Ignoring Assert operator compile_loss/masked_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "W0000 00:00:1728819703.496604   35694 assert_op.cc:38] Ignoring Assert operator compile_loss/masked_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 16ms/step - loss: 7.2803 - masked_accuracy: 0.1540 - val_loss: 3.8010 - val_masked_accuracy: 0.4980\n",
      "Epoch 2/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 3.7914 - masked_accuracy: 0.5139 - val_loss: 2.8757 - val_masked_accuracy: 0.6121\n",
      "Epoch 3/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 2.8615 - masked_accuracy: 0.6194 - val_loss: 2.3696 - val_masked_accuracy: 0.6798\n",
      "Epoch 4/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 2.4045 - masked_accuracy: 0.6748 - val_loss: 2.2141 - val_masked_accuracy: 0.6975\n",
      "Epoch 5/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 2.2049 - masked_accuracy: 0.6989 - val_loss: 2.1489 - val_masked_accuracy: 0.7066\n",
      "Epoch 6/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 2.0798 - masked_accuracy: 0.7141 - val_loss: 2.1007 - val_masked_accuracy: 0.7105\n",
      "Epoch 7/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 1.9869 - masked_accuracy: 0.7255 - val_loss: 2.0766 - val_masked_accuracy: 0.7151\n",
      "Epoch 8/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 1.9115 - masked_accuracy: 0.7348 - val_loss: 2.0530 - val_masked_accuracy: 0.7177\n",
      "Epoch 9/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 1.8494 - masked_accuracy: 0.7434 - val_loss: 2.0481 - val_masked_accuracy: 0.7200\n",
      "Epoch 10/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 1.7958 - masked_accuracy: 0.7506 - val_loss: 2.0447 - val_masked_accuracy: 0.7211\n",
      "Epoch 11/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 1.7497 - masked_accuracy: 0.7575 - val_loss: 2.0378 - val_masked_accuracy: 0.7204\n",
      "Epoch 12/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 1.7090 - masked_accuracy: 0.7628 - val_loss: 2.0451 - val_masked_accuracy: 0.7232\n",
      "Epoch 13/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 1.6696 - masked_accuracy: 0.7685 - val_loss: 2.0396 - val_masked_accuracy: 0.7239\n",
      "Epoch 14/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 1.6359 - masked_accuracy: 0.7733 - val_loss: 2.0446 - val_masked_accuracy: 0.7259\n",
      "Epoch 15/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 1.6053 - masked_accuracy: 0.7778 - val_loss: 2.0610 - val_masked_accuracy: 0.7258\n",
      "Epoch 16/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 1.5772 - masked_accuracy: 0.7817 - val_loss: 2.0632 - val_masked_accuracy: 0.7235\n",
      "Epoch 17/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 1.5523 - masked_accuracy: 0.7858 - val_loss: 2.0721 - val_masked_accuracy: 0.7233\n",
      "Epoch 18/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 1.5275 - masked_accuracy: 0.7894 - val_loss: 2.0760 - val_masked_accuracy: 0.7245\n",
      "Epoch 19/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 1.5052 - masked_accuracy: 0.7928 - val_loss: 2.0841 - val_masked_accuracy: 0.7263\n",
      "Epoch 20/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 1.4861 - masked_accuracy: 0.7954 - val_loss: 2.0895 - val_masked_accuracy: 0.7256\n",
      "Epoch 21/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 1.4658 - masked_accuracy: 0.7984 - val_loss: 2.1007 - val_masked_accuracy: 0.7250\n",
      "Epoch 22/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 1.4485 - masked_accuracy: 0.8008 - val_loss: 2.1041 - val_masked_accuracy: 0.7252\n",
      "Epoch 23/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 1.4316 - masked_accuracy: 0.8034 - val_loss: 2.1123 - val_masked_accuracy: 0.7266\n",
      "Epoch 24/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 1.4167 - masked_accuracy: 0.8056 - val_loss: 2.1184 - val_masked_accuracy: 0.7240\n",
      "Epoch 25/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 1.4022 - masked_accuracy: 0.8073 - val_loss: 2.1195 - val_masked_accuracy: 0.7272\n",
      "Epoch 26/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 1.3869 - masked_accuracy: 0.8101 - val_loss: 2.1228 - val_masked_accuracy: 0.7272\n",
      "Epoch 27/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 1.3751 - masked_accuracy: 0.8116 - val_loss: 2.1434 - val_masked_accuracy: 0.7257\n",
      "Epoch 28/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 1.3624 - masked_accuracy: 0.8135 - val_loss: 2.1436 - val_masked_accuracy: 0.7286\n",
      "Epoch 29/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 1.3495 - masked_accuracy: 0.8154 - val_loss: 2.1535 - val_masked_accuracy: 0.7274\n",
      "Epoch 30/30\n",
      "\u001b[1m2174/2174\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 1.3384 - masked_accuracy: 0.8171 - val_loss: 2.1517 - val_masked_accuracy: 0.7279\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "dense_dim = 1024\n",
    "num_heads = 8\n",
    "\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(dutch_maxlen,), dtype=\"int64\", name=\"dutch\")\n",
    "decoder_inputs = keras.Input(shape=(frisian_maxlen,), dtype=\"int64\", name=\"frisian\")\n",
    "\n",
    "# encoder_embedding = TokenAndPositionEmbedding(dutch_vocab_size, dutch_maxlen, embed_dim)(encoder_inputs)\n",
    "encoder_embedding = PositionalEmbedding(dutch_maxlen, dutch_vocab_size, embed_dim, name=\"encoder_embedding\")(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads, name=\"encoder_outputs\")(encoder_embedding)\n",
    "\n",
    "\n",
    "# decoder_embedding = TokenAndPositionEmbedding(frisian_vocab_size, frisian_maxlen, embed_dim)(decoder_inputs)\n",
    "decoder_embedding = PositionalEmbedding(frisian_maxlen, frisian_vocab_size, embed_dim, name=\"decoder_embedding\")(decoder_inputs)\n",
    "decoder = TransformerDecoder(embed_dim, dense_dim, num_heads, name=\"decoder\")(decoder_embedding, encoder_outputs)\n",
    "\n",
    "\n",
    "decoder_dropout = layers.Dropout(0.5, name=\"decoder_dropout\")(decoder)\n",
    "decoder_outputs = layers.Dense(frisian_vocab_size, activation=\"softmax\", name=\"decoder_outputs\")(decoder_dropout)\n",
    "\n",
    "\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()\n",
    "\n",
    "learning_rate = CustomSchedule(embed_dim)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)\n",
    "\n",
    "model.compile(\n",
    "    loss=masked_loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[masked_accuracy])\n",
    "\n",
    "history = model.fit(train_ds, epochs=30, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f14c4254a90>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc=history.history['masked_accuracy']\n",
    "val_acc=history.history['val_masked_accuracy']\n",
    "epochs=range(1, len(acc)+1)\n",
    "plt.plot(epochs, acc, label='accuracy')\n",
    "plt.plot(epochs, val_acc, label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Tekst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tekst"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
